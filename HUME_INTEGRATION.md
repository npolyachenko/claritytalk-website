# Hume AI Integration - Quick Start Guide

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Hume AI (Octave TTS + Voice Analysis) –≤ ClarityTalk –∑–∞–≤–µ—Ä—à–µ–Ω–∞! üéâ

## –ß—Ç–æ –±—ã–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ

### 1. **Backend Server** (`/server`)
- Express.js –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Hume AI API
- 2 —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞:
  - `/api/tts` - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ —Å —ç–º–æ—Ü–∏—è–º–∏
  - `/api/analyze-voice` - –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ –Ω–∞ 48 —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫

### 2. **Frontend Features** (`sample-report.html`)
- **–ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å (Vocal Expression Analysis)**: –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ + –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–æ—Ü–∏–π
- **–ü–æ—Å–ª—É—à–∞–π —Ä–∞–∑–Ω–∏—Ü—É**: –¥–µ–º–æ TTS —Å 4 —ç–º–æ—Ü–∏—è–º–∏ (—Å–ø–æ–∫–æ–π–Ω–æ, —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–Ω–æ, —Å –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ–º, —Å –ª—é–±–æ–≤—å—é)

### 3. **New Files Created**
```
server/
‚îú‚îÄ‚îÄ package.json        # Dependencies
‚îú‚îÄ‚îÄ server.js           # Express server with API endpoints
‚îú‚îÄ‚îÄ .env               # API key configuration
‚îú‚îÄ‚îÄ .env.example       # Template for .env
‚îî‚îÄ‚îÄ README.md          # Detailed documentation

js/
‚îî‚îÄ‚îÄ emotion-demo.js    # Frontend logic for TTS demo & voice analysis

css/
‚îî‚îÄ‚îÄ emotion-styles.css # Styling for new components
```

## üöÄ –ó–∞–ø—É—Å–∫

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd server
npm install
```

### –®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–∞

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `server/.env` –∏ –¥–æ–±–∞–≤—å—Ç–µ –≤–∞—à Hume AI API –∫–ª—é—á:

```bash
HUME_API_KEY=–≤–∞—à_—Ä–µ–∞–ª—å–Ω—ã–π_–∫–ª—é—á_–∑–¥–µ—Å—å
PORT=3001
```

### –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞

```bash
# –í –ø–∞–ø–∫–µ server/
npm start

# –ò–ª–∏ —Å –∞–≤—Ç–æ-–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–æ–π (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
npm run dev
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞**: –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:3001/health –≤ –±—Ä–∞—É–∑–µ—Ä–µ

### –®–∞–≥ 4: –ó–∞–ø—É—Å–∫ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞

–û—Ç–∫—Ä–æ–π—Ç–µ `sample-report.html` –≤ –±—Ä–∞—É–∑–µ—Ä–µ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä:

```bash
# –í–∞—Ä–∏–∞–Ω—Ç 1: Python
python -m http.server 8000

# –í–∞—Ä–∏–∞–Ω—Ç 2: Node.js http-server
npx http-server

# –í–∞—Ä–∏–∞–Ω—Ç 3: PHP
php -S localhost:8000
```

–ó–∞—Ç–µ–º –æ—Ç–∫—Ä–æ–π—Ç–µ: http://localhost:8000/sample-report.html

## ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π

### –§—É–Ω–∫—Ü–∏—è 1: "–ü–æ—Å–ª—É—à–∞–π —Ä–∞–∑–Ω–∏—Ü—É" (TTS Demo)

1. Scroll down `sample-report.html` to the **"Hear the Difference"** section
2. Click any of the buttons:
   - üòå Calm
   - üò† Irritated
   - üòü Anxious
   - ‚ù§Ô∏è Loving
3. Wait 3-5 seconds (speech generation)
4. Audio player will appear ‚Äî click Play
5. Try all 4 emotions and hear the difference!

**What we're testing:**
- ‚úÖ Buttons are clickable
- ‚úÖ Loading state (button becomes transparent with spinner)
- ‚úÖ Audio is generated and plays
- ‚úÖ Different emotional coloring of voice

### Function 2: Vocal Expression Analysis

1. Prepare an audio file (MP3, WAV, M4A up to 10MB)
   - You can record a voice message on your phone
   - Or use any existing audio file with speech
2. In the **"Vocal Expression Analysis"** section, click **"üìÅ Upload and Analyze Audio"**
3. Select audio file
4. Wait for analysis (may take up to 2 minutes)
5. You'll see the top 15 emotional characteristics with percentages and colored bars

**What we're testing:**
- ‚úÖ File uploads without errors
- ‚úÖ Loading spinner appears
- ‚úÖ Results display with animation
- ‚úÖ Color coding (green = positive, red = negative, blue = neutral)

## üêõ Troubleshooting

### Server won't start

**Error**: `Cannot find module 'express'`
```bash
cd server && npm install
```

**Error**: `HUME_API_KEY is not configured`
- Check that `server/.env` file exists
- Make sure it contains the correct API key
- Restart the server

### CORS errors in browser

**Problem**: `Access-Control-Allow-Origin`
- Make sure server is running on port 3001
- Check that frontend is opened via `http://localhost:8000`, not `file://`

### TTS doesn't work

1. Check browser console (F12 ‚Üí Console)
2. Check server logs in terminal
3. Make sure API key is valid and has TTS access
4. Try shorter text

### Voice Analysis timeout

- File too large ‚Üí reduce to < 5MB
- File too long ‚Üí trim to < 2 minutes
- Hume API issues ‚Üí check https://status.hume.ai

## üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Browser (sample-report.html)       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ emotion-demo.js                ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ EmotionTTSDemo             ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ VoiceAnalyzer              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ emotion-styles.css             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ HTTP/JSON
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Express Server (localhost:3001)    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ POST /api/tts                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ POST /api/analyze-voice        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ API Key
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Hume AI Cloud                      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Octave TTS API                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Expression Measurement API      ‚îÇ
‚îÇ      (Prosody Model)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

### Add new emotions for TTS

Edit `server/server.js`, add to `emotionDescriptions`:

```javascript
const emotionDescriptions = {
  calm: '...',
  irritated: '...',
  anxious: '...',
  loving: '...',
  excited: 'speaking with high energy and enthusiasm' // ‚Üê new emotion
};
```

Then add button in `sample-report.html`:
```html
<button data-emotion="excited">ü§© Excited</button>
```

### Show more emotions

In `js/emotion-demo.js` change the line:

```javascript
const topEmotions = emotions.slice(0, 15); // ‚Üê change 15 to 48
```

### Cache TTS

Add caching in `js/emotion-demo.js`:

```javascript
// At the beginning of EmotionTTSDemo class
this.audioCache = new Map();

// In generateSpeech method, before fetch:
const cacheKey = `${text}_${emotion}`;
if (this.audioCache.has(cacheKey)) {
  await this.playAudio(this.audioCache.get(cacheKey));
  return;
}

// After getting audioChunks:
this.audioCache.set(cacheKey, audioChunks);
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–î–µ—Ç–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–µ—Ä–≤–µ—Ä–∞**: `server/README.md`
- **Hume AI Docs**: https://dev.hume.ai/
- **Hume AI Discord**: https://discord.gg/hume

## ‚ú® What's Next?

1. **Add real-time analysis**: use Hume Streaming API for real-time analysis
2. **Integrate into main report**: add voice analysis for both speakers
3. **Visualizations**: add emotion graphs over time (charts.js)
4. **Save results**: store analyses in localStorage or backend
5. **Comparison**: show difference between two recordings of the same person

---

**Ready for testing!** üéâ

If you have questions ‚Äî see `server/README.md` or write in the repository issues.
